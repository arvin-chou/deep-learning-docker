{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD300 MS COCO Evaluation Tutorial\n",
    "### Reference: https://github.com/pierluigiferrari/ssd_keras/blob/master/ssd300_evaluation_COCO.ipynb \n",
    "- Evaluate a trained SSD300 on one of the MS COCO datasets using the official MS COCO Python tools available here: https://github.com/cocodataset/cocoapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "# TODO: Specify the directory that contains the `pycocotools` here.\n",
    "pycocotools_dir = '/datasets/coco_2017/cocoapi-master/PythonAPI/'\n",
    "if pycocotools_dir not in sys.path:\n",
    "    sys.path.insert(0, pycocotools_dir)\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from keras_ssd300 import ssd_300\n",
    "from keras_ssd_loss import SSDLoss\n",
    "from keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layer_L2Normalization import L2Normalization\n",
    "from ssd_batch_generator import BatchGenerator\n",
    "from coco_utils import get_coco_category_maps, predict_all_to_json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input image size for the model.\n",
    "img_height = 300\n",
    "img_width = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load a trained SSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/ssd300_coco_2017.h5'\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, n_neg_min=0, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'L2Normalization': L2Normalization,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a data generator for the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BatchGenerator(box_output_format=['class_id', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "# TODO: Set the paths to the dataset here.\n",
    "MS_COCO_dataset_images_dir = '/datasets/coco_2017/val2017/'\n",
    "MS_COCO_dataset_annotations_filename = '/datasets/coco_2017/annotations/instances_val2017.json'\n",
    "\n",
    "dataset.parse_json(images_dirs=[MS_COCO_dataset_images_dir],\n",
    "                   annotations_filenames=[MS_COCO_dataset_annotations_filename],\n",
    "                   ground_truth_available=False, # It doesn't matter whether you set this `True` or `False` because the ground truth won't be used anyway, but the parsing goes faster if you don't load the ground truth.\n",
    "                   include_classes='all',\n",
    "                   ret=False)\n",
    "\n",
    "# We need the `classes_to_cats` dictionary. Read the documentation of this function to understand why.\n",
    "cats_to_classes, classes_to_cats, cats_to_names, classes_to_names = get_coco_category_maps(MS_COCO_dataset_annotations_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run the predictions over the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the desired output file name and the batch size.\n",
    "results_file = 'detections_val2017_ssd300_results.json'\n",
    "batch_size = 20 # Ideally, choose a batch size that divides the number of images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_all_to_json(out_file=results_file,\n",
    "                    model=model,\n",
    "                    img_height=img_height,\n",
    "                    img_width=img_width,\n",
    "                    classes_to_cats=classes_to_cats,\n",
    "                    batch_generator=dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    batch_generator_mode='resize',\n",
    "                    confidence_thresh=0.01,\n",
    "                    iou_threshold=0.45,\n",
    "                    top_k=200,\n",
    "                    pred_coords='centroids',\n",
    "                    normalize_coords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_gt   = COCO(MS_COCO_dataset_annotations_filename)\n",
    "coco_dt   = coco_gt.loadRes(results_file)\n",
    "image_ids = sorted(coco_gt.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoEval = COCOeval(cocoGt=coco_gt,\n",
    "                    cocoDt=coco_dt,\n",
    "                    iouType='bbox')\n",
    "cocoEval.params.imgIds  = image_ids\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
